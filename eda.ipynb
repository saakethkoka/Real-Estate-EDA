{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Realtor.com Dataset:\n",
    "\n",
    "## Business Case:\n",
    "\n",
    "This dataset can be used to understand historical trends in US Housing data which can be leveraged to project future pricing. Further, the dataset could be used to compare a house which is for sale with what the market is pricing comparable sales too. This allows homeowners and investors to make more educated decisions with regards to real estate purchases.\n",
    "\n",
    "USA Real Estate Dataset  is a 12 feature 900,000+ entry dataset of the Real Estate transactions and the properties on the market for various markets across the United States. The dataset is collected from a weekly web scrape of the Realtor.com website which is one of the USâ€™ most popular provider of real estate data and has historical data going back to 1980s.\n",
    "\n",
    "The business model of a real estate flipper is to purchase a property which is in a below market state, renovate that property, and then sell that property at a price which covers the initial purchase price and renovations. For this business model to succeed, the flipper needs to have an accurate After Repair Value (ARV) which is the fair market value of the property when the repairs are completed. To get the ARV, the flipper needs to project both what the fair market value of the house if it were repaired and the way in which the market will change between now and the time in which renovation finishes. Due to the locality of the real estate market, trends in the national housing market cannot accurately indicate what will happen to the value of houses in different price ranges and markets. As a result, to get a good indication of ARV comparison with comparable sales must be conducted. Our dataset allows for a programmatic determination of ARV by using comparable sales and by finding market trends amongst those sales.\n",
    "\n",
    "\n",
    "## Threashold\n",
    "\n",
    "\n",
    "The threshold for this tool being valuable is whether or not it provides a better estimation than human evaluators.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing Relevant Libraries:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 923159 entries, 0 to 923158\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   status        923159 non-null  object \n",
      " 1   price         923088 non-null  float64\n",
      " 2   bed           791456 non-null  float64\n",
      " 3   bath          807967 non-null  float64\n",
      " 4   acre_lot      649536 non-null  float64\n",
      " 5   full_address  923159 non-null  object \n",
      " 6   street        921021 non-null  object \n",
      " 7   city          923085 non-null  object \n",
      " 8   state         923159 non-null  object \n",
      " 9   zip_code      922954 non-null  float64\n",
      " 10  house_size    625316 non-null  float64\n",
      " 11  sold_date     456396 non-null  object \n",
      "dtypes: float64(6), object(6)\n",
      "memory usage: 84.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"realtor-data.csv\")\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Understanding the data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "     status     price  bed  bath  acre_lot  \\\n0  for_sale  105000.0  3.0   2.0      0.12   \n1  for_sale   80000.0  4.0   2.0      0.08   \n2  for_sale   67000.0  2.0   1.0      0.15   \n3  for_sale  145000.0  4.0   2.0      0.10   \n4  for_sale   65000.0  6.0   2.0      0.05   \n5  for_sale  179000.0  4.0   3.0      0.46   \n6  for_sale   50000.0  3.0   1.0      0.20   \n7  for_sale   71600.0  3.0   2.0      0.08   \n8  for_sale  100000.0  2.0   1.0      0.09   \n9  for_sale  300000.0  5.0   3.0      7.46   \n\n                                        full_address  \\\n0  Sector Yahuecas Titulo # V84, Adjuntas, PR, 00601   \n1            Km 78 9 Carr # 135, Adjuntas, PR, 00601   \n2            556G 556-G 16 St, Juana Diaz, PR, 00795   \n3  R5 Comunidad El Paraso Calle De Oro R-5 Ponce,...   \n4                    14 Navarro, Mayaguez, PR, 00680   \n5  Bo Calabazas San Sebastian, San Sebastian, PR,...   \n6                        49.1 140, Ciales, PR, 00639   \n7                          3467 St, Ponce, PR, 00731   \n8                  230 Rio De Vida, Ponce, PR, 00730   \n9  Pr 120 Bo Maravilla Sur K M # 335, Las Marias,...   \n\n                                          street           city        state  \\\n0                   Sector Yahuecas Titulo # V84       Adjuntas  Puerto Rico   \n1                             Km 78 9 Carr # 135       Adjuntas  Puerto Rico   \n2                               556G 556-G 16 St     Juana Diaz  Puerto Rico   \n3  R5 Comunidad El Paraso Calle De Oro R-5 Ponce          Ponce  Puerto Rico   \n4                                     14 Navarro       Mayaguez  Puerto Rico   \n5                     Bo Calabazas San Sebastian  San Sebastian  Puerto Rico   \n6                                       49.1 140         Ciales  Puerto Rico   \n7                                        3467 St          Ponce  Puerto Rico   \n8                                230 Rio De Vida          Ponce  Puerto Rico   \n9              Pr 120 Bo Maravilla Sur K M # 335     Las Marias  Puerto Rico   \n\n   zip_code  house_size sold_date  \n0     601.0       920.0       NaN  \n1     601.0      1527.0       NaN  \n2     795.0       748.0       NaN  \n3     731.0      1800.0       NaN  \n4     680.0         NaN       NaN  \n5     612.0      2520.0       NaN  \n6     639.0      2040.0       NaN  \n7     731.0      1050.0       NaN  \n8     730.0      1092.0       NaN  \n9     670.0      5403.0       NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>status</th>\n      <th>price</th>\n      <th>bed</th>\n      <th>bath</th>\n      <th>acre_lot</th>\n      <th>full_address</th>\n      <th>street</th>\n      <th>city</th>\n      <th>state</th>\n      <th>zip_code</th>\n      <th>house_size</th>\n      <th>sold_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>for_sale</td>\n      <td>105000.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.12</td>\n      <td>Sector Yahuecas Titulo # V84, Adjuntas, PR, 00601</td>\n      <td>Sector Yahuecas Titulo # V84</td>\n      <td>Adjuntas</td>\n      <td>Puerto Rico</td>\n      <td>601.0</td>\n      <td>920.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>for_sale</td>\n      <td>80000.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>0.08</td>\n      <td>Km 78 9 Carr # 135, Adjuntas, PR, 00601</td>\n      <td>Km 78 9 Carr # 135</td>\n      <td>Adjuntas</td>\n      <td>Puerto Rico</td>\n      <td>601.0</td>\n      <td>1527.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>for_sale</td>\n      <td>67000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.15</td>\n      <td>556G 556-G 16 St, Juana Diaz, PR, 00795</td>\n      <td>556G 556-G 16 St</td>\n      <td>Juana Diaz</td>\n      <td>Puerto Rico</td>\n      <td>795.0</td>\n      <td>748.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>for_sale</td>\n      <td>145000.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>0.10</td>\n      <td>R5 Comunidad El Paraso Calle De Oro R-5 Ponce,...</td>\n      <td>R5 Comunidad El Paraso Calle De Oro R-5 Ponce</td>\n      <td>Ponce</td>\n      <td>Puerto Rico</td>\n      <td>731.0</td>\n      <td>1800.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>for_sale</td>\n      <td>65000.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>0.05</td>\n      <td>14 Navarro, Mayaguez, PR, 00680</td>\n      <td>14 Navarro</td>\n      <td>Mayaguez</td>\n      <td>Puerto Rico</td>\n      <td>680.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>for_sale</td>\n      <td>179000.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>0.46</td>\n      <td>Bo Calabazas San Sebastian, San Sebastian, PR,...</td>\n      <td>Bo Calabazas San Sebastian</td>\n      <td>San Sebastian</td>\n      <td>Puerto Rico</td>\n      <td>612.0</td>\n      <td>2520.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>for_sale</td>\n      <td>50000.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.20</td>\n      <td>49.1 140, Ciales, PR, 00639</td>\n      <td>49.1 140</td>\n      <td>Ciales</td>\n      <td>Puerto Rico</td>\n      <td>639.0</td>\n      <td>2040.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>for_sale</td>\n      <td>71600.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.08</td>\n      <td>3467 St, Ponce, PR, 00731</td>\n      <td>3467 St</td>\n      <td>Ponce</td>\n      <td>Puerto Rico</td>\n      <td>731.0</td>\n      <td>1050.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>for_sale</td>\n      <td>100000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.09</td>\n      <td>230 Rio De Vida, Ponce, PR, 00730</td>\n      <td>230 Rio De Vida</td>\n      <td>Ponce</td>\n      <td>Puerto Rico</td>\n      <td>730.0</td>\n      <td>1092.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>for_sale</td>\n      <td>300000.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>7.46</td>\n      <td>Pr 120 Bo Maravilla Sur K M # 335, Las Marias,...</td>\n      <td>Pr 120 Bo Maravilla Sur K M # 335</td>\n      <td>Las Marias</td>\n      <td>Puerto Rico</td>\n      <td>670.0</td>\n      <td>5403.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO For each of the following:\n",
    "\n",
    "appropriately define data types. What data type should be used to represent each data attribute? Discuss the attributes collected in the dataset. For datasets with a large number of attributes, only discuss a subset of relevant attributes.\n",
    "\n",
    "Verify data quality: Explain any missing values or duplicate data. Visualize entries that are missing/complete for different attributes. Are those mistakes? Why do these quality issues exist in the data? How do you deal with these problems? Give justifications for your methods (elimination or imputation).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### status: Saaketh\n",
    "\n",
    "The status feature tells whether the given listing was for_sale or ready_to_build. This feature should be one-hot encoded. Because there are only two values for status, we will only the ready_to_build column. After the transformation, the status column will be replaced with a read_to_build column."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "for_sale          921528\nready_to_build      1631\nName: status, dtype: int64"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.status.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "'Number of missing values: 0'"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Number of missing values: \" +   str(df.status.isna().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only 1,631 out of the 923,159 listings were labeled as ready_to_build\n",
    "\n",
    "OneHotEncoding the ready_to_build column\n",
    "We will also drop the original column after one hot encoding."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "df[\"ready_to_build\"] = pd.get_dummies(df.status).ready_to_build\n",
    "df.drop(columns=[\"status\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### price: Ray\n",
    "\n",
    "Price is feature which we are trying to predict. The price feature is the value at which is the house has sold for. Price is a float because it is a numeric value.\n",
    "\n",
    "First we should see if there are any missing price data..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"Number of missing values: \" +   str(df.price.isna().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because all of the other metrics (square footage, number of baths, number of bedrooms) are used to predict price, if the price value is missing the data for that entry is not of any value and should be dropped as a result."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.dropna(subset=['price'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have dropped all of the null values, let's look at the distribution of the price data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x=\"price\", kde=True, bins=50000,kde_kws={'clip' : (0, 1500000)})\n",
    "plt.xlim(0, 1500000)\n",
    "print(\"The mean is: \" + str(df['price'].mean()))\n",
    "print(\"The standard deviation is: \" + str(df['price'].std()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As the histogram shows, the distribution of price data is unimodal with a left skew."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### bed: Vedant\n",
    "#The bed column gives a count of the number of bedrooms in a given property, the value is an integer but is stored as a float in pandas, I have a suspicion that this means there are some missing values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#As suspected, we have a lot of missing values, over 12000, but this is only about 13% of our dataset so we can just drop the missing rows, as there is stilla a lot of useful information in this feature.\n",
    "# this python magics will allow plot to be embedded into the notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline\n",
    "\n",
    "# External package: conda install missingno\n",
    "import missingno as mn\n",
    "\n",
    "mn.matrix(df)\n",
    "plt.title(\"Not Sorted\",fontsize=22)\n",
    "\n",
    "plt.figure()\n",
    "mn.matrix(df.sort_values(by=[\"bed\"]))\n",
    "plt.title(\"Sorted\",fontsize=22)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From this visual, it seems that the missing values of bed are also highly indicative of missing values in bath(# bathrooms), house size and sold date. That honestly doesn't give much confidence that imputation would actually work super well with this dataset for either of those features (as they are hightly correlated to each other) so lets just drop the missing columns of bed."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.dropna(subset=['bed'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### bath: Saaketh\n",
    "\n",
    "This variable describes the number of bathrooms in the property. The data is in Integer form."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "txt = \"{percent:.2f}% of the data is missing\"\n",
    "print(txt.format(percent=(df.bath.isna().sum()*100) / len(df)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because 12% of the data is missing we can impute the bed variable with nearest K nearest neighbors imputation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### acre_lot\n",
    "\n",
    "#### Overview\n",
    "The acre_lot feature indicates the lot size of the property being sold. This feature is different from the house size metric as that measures the size of the property itself rather than the land around it. While this difference is often negligable in urban areas, for rural properties, the Lot Size of the land often drives the value of the property more than the value of the dwelling. The variable type of acre lot is float because it represents a non-discrete numeric value.\n",
    "\n",
    "#### Missing Values\n",
    "The first questions is what percentage of the data does not have a acre_lot value."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "str(int((df.acre_lot.isna().sum())/ len(df) * 100)) + \"% do not have acre_lot\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we dropped all attributes that do not have an acre_lot value then about 1/3 of the data would be lost. This is a signifigant loss of data which could reduce the ability for our model to predict the value of price. To mitigate this, we will try to see if imputing this data is a wise decision and if it is, we will impute it.\n",
    "\n",
    "If acre lot can mostly be predicted from another feature than imputing it is a good idea. One canidate for this is house size. House size measures the amount of square feet within the house. As a general rule, houses with larger interiors should have larger exteriors. To test to see if this is a valid presumption, we'll generate a scatter plot of the data comparing these two features to see if a linearity exists."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.regplot(df,x=\"house_size\",y=\"acre_lot\",fit_reg=True)\n",
    "plt.xlim(0, 20000)\n",
    "plt.ylim(0,2.50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As the scatter plot shows, all of the points are bunched on the left side of the plot. As a result, we cannot have faith in the regression model which would be produced. Due to the high importance of acre_lot to determine the value of a property, we will be dropping all of the entries that do not have a acre_lot value."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.dropna(subset=['acre_lot'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# full_address: Vedant\n",
    "\n",
    "Because we already have zip code and other useful geolocation data, the full address isn't all that relevant to us, as the full address itself doesn't inherently provide more information to us than zip code, unless we wanted to somehow map the addresses to precise places via a gps, which would likely be exrtremely expensive and beyond the scope of what we can realistically do, given our current limitations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#dropping the address feature\n",
    "df.drop(labels=['full_address'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### street: Saaketh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241m.\u001B[39mstreet\u001B[38;5;241m.\u001B[39misna()\u001B[38;5;241m.\u001B[39msum()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.street.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop(labels=['street'], axis=1, inplace=True])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### city: Ray\n",
    "\n",
    "The city indicates the city in which the property is located. The value of city is one hot-encoded. This is feature allows us to determine the market which the property is located and to use that propertie's price data to make market predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.city.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see from the above snipit, all entries that remain in the dataframe have a city feature. As a result, we do not need to change the dataframe."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.city.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The top two values for city are New York and New York City which refer to the same location. Further, there are various cities that have a small number of properties located in them."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### state: Vedant"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.state.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are no missing values for state and it is useful for the purposes of mapping, dicretizing the data by state, etc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.state.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#dropping virgin islands because it only has 6 instances and is therefore not all that useful\n",
    "df = df[df.state.isin([\"Virgin Islands\"]) == False]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### zip_code: Saaketh\n",
    "\n",
    "In the US, a Zip Code is 5 digits. Any entries in the zip code feature that have less than 5 digits have leading 0s in their official zipcode."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.zip_code.min(), df.zip_code.max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.zip_code.isna().sum(), (df.zip_code.isna().sum()*100)/len(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are only 205 NaN values for the zip_code feature. These account for ~0.02% of the dataset. For this reason, we will eliminate the NaN values. If we had more NaN values, we could impute by taking the mode zipcode grouped by city. This is using the logic that a single zipcode covers most of the city."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"zip_code\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO if bored: Encode this"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sold date has about 362,000 missing values, isn't really something we can impute due to the fact that there are a very high number of sold dates in our dataset and there is no real notion that the nearest neaighbords across some feature will have similar dates due to a missing one. However, this feature is very important for us in terms of understanding shifts over time, so we will just drop rows with missing values."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"sold_date\"] = pd.to_datetime(df[\"sold_date\"])\n",
    "df.sold_date.isna().sum()\n",
    "df.dropna(subset=['sold_date'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"sold_date\"] = pd.to_datetime(df[\"sold_date\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Visualization:\n",
    "\n",
    "TODO: Ask three interesting questions that are relevant to your dataset and explore visuals that help answer these questions. Use whichever visualization method is appropriate for your data\n",
    "Visualize basic feature distributions. That is, plot the dynamic range and exploratory distribution plots (like boxplots, histograms, kernel density estimation) to better understand the data. Describe anything meaningful or potentially useful you discover from these visualizations. These may also help to understand what data is missing or needs imputation. Note: You can also use data from other sources to bolster visualizations. Visualize at least five plots, at least one categorical.\n",
    "\n",
    "\n",
    "We will each do 2 plots\n",
    "\n",
    "Question ideas:\n",
    "\n",
    "\n",
    "How do house prices vary by location?\n",
    "How do house prices vary by size / features of the house?\n",
    "How have house prices changed over time?\n",
    "How have house features changed over time? (ie have bedrooms / bathrooms increased in number, sqft increased or decreased, ect.)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the correlation matrix\n",
    "vars_to_use = ['bed', 'bath', 'acre_lot', 'house_size', 'price'] # pick vars\n",
    "plt.pcolor(df[vars_to_use].corr()) # do the feature correlation plot\n",
    "\n",
    "# fill in the indices\n",
    "plt.yticks(np.arange(0.5, len(vars_to_use), 1), vars_to_use)\n",
    "plt.xticks(np.arange(0.5, len(vars_to_use), 1), vars_to_use)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How do house prices vary by location? Saaketh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import datetime as dt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I am getting the values from 2011 onwards in order to keep the prices relatively recent."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['sold_date'] = pd.to_datetime(df[\"sold_date\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "states_df = df[df.sold_date > dt.datetime(2011,1,1)].groupby(\"state\").mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with urlopen('https://raw.githubusercontent.com/PublicaMundi/MappingAPI/master/data/geojson/us-states.json') as response:\n",
    "    states = json.load(response)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "states_to_number = {\n",
    "    # State_name :  state id\n",
    "}\n",
    "\n",
    "for state in states[\"features\"]:\n",
    "    state_name = state[\"properties\"][\"name\"]\n",
    "    state_id = state[\"id\"]\n",
    "\n",
    "    states_to_number[state_name] = state_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "states_to_number = {\n",
    "    # State_name :  state id\n",
    "}\n",
    "\n",
    "for state in states[\"features\"]:\n",
    "    state_name = state[\"properties\"][\"name\"]\n",
    "    state_id = state[\"id\"]\n",
    "\n",
    "    states_to_number[state_name] = state_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def label_state_id(row):\n",
    "    try:\n",
    "        state_id = states_to_number[row.name]\n",
    "    except:\n",
    "        return 0\n",
    "    return state_id\n",
    "states_df[\"state_id\"] = states_df.apply(label_state_id, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.choropleth(states_df,\n",
    "              locations= states_df.state_id,\n",
    "              geojson=states,\n",
    "              color='price',\n",
    "              color_continuous_scale=\"Viridis\",\n",
    "              range_color=(300000, 1500000),\n",
    "              scope=\"usa\",\n",
    "              labels={'unemp':'unemployment rate'},\n",
    "              title=\"Average sold house price since 2011 by state\"\n",
    "              )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since 2011 the state of New York has had the highest average house prices of all the other states in our dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recent_sold_homes = df[df.sold_date > dt.datetime(2011,1,1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.violin(recent_sold_homes, x=\"price\", animation_frame=\"state\", title=\"Distribution of sold home prices by state\")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Most states have a uni-modal distribution in their house prices. Georgia has a bi-modal distribution but only has 36 data points after 2011. New Hampshire's price distribution is more tightly concentrated compared to that of New York's price distribution. New York has more spread in the prices than other states in the dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 2: Ray\n",
    "In what ways is the housing market localized?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.violin(recent_sold_homes, x=\"price\", animation_frame=\"state\")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How do house prices vary by location? Saaketh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [76]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mplotly\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexpress\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpx\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01murllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrequest\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m urlopen\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import datetime as dt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I am getting the values from 2011 onwards in order to keep the prices relatively recent."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['sold_date'] = pd.to_datetime(df[\"sold_date\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "states_df = df[df.sold_date > dt.datetime(2011,1,1)].groupby(\"state\").mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with urlopen('https://raw.githubusercontent.com/PublicaMundi/MappingAPI/master/data/geojson/us-states.json') as response:\n",
    "    states = json.load(response)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "states_to_number = {\n",
    "    # State_name :  state id\n",
    "}\n",
    "\n",
    "for state in states[\"features\"]:\n",
    "    state_name = state[\"properties\"][\"name\"]\n",
    "    state_id = state[\"id\"]\n",
    "\n",
    "    states_to_number[state_name] = state_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "states_to_number = {\n",
    "    # State_name :  state id\n",
    "}\n",
    "\n",
    "for state in states[\"features\"]:\n",
    "    state_name = state[\"properties\"][\"name\"]\n",
    "    state_id = state[\"id\"]\n",
    "\n",
    "    states_to_number[state_name] = state_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def label_state_id(row):\n",
    "    try:\n",
    "        state_id = states_to_number[row.name]\n",
    "    except:\n",
    "        return 0\n",
    "    return state_id\n",
    "states_df[\"state_id\"] = states_df.apply(label_state_id, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.choropleth(states_df,\n",
    "              locations= states_df.state_id,\n",
    "              geojson=states,\n",
    "              color='price',\n",
    "              color_continuous_scale=\"Viridis\",\n",
    "              range_color=(300000, 1500000),\n",
    "              scope=\"usa\",\n",
    "              labels={'unemp':'unemployment rate'},\n",
    "              title=\"Average sold house price since 2011 by state\"\n",
    "              )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since 2011 the state of New York has had the highest average house prices of all the other states in our dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recent_sold_homes = df[df.sold_date > dt.datetime(2011,1,1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.violin(recent_sold_homes, x=\"price\", animation_frame=\"state\", title=\"Distribution of sold home prices by state\")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Most states have a uni-modal distribution in their house prices. Georgia has a bi-modal distribution but only has 36 data points after 2011. New Hampshire's price distribution is more tightly concentrated compared to that of New York's price distribution. New York has more spread in the prices than other states in the dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 2: Ray\n",
    "In what ways is the housing market localized?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.violin(recent_sold_homes, x=\"price\", animation_frame=\"state\")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}